timestamp,question,intent,confidence,gap,mode,response_length,time_taken_sec,sources,prompt,answer
2025-10-28T15:57:59.676703,what is the introduction pdf talking about,retrieval,0.247,0.11,auto,671,39.47,"**/Users/kousiknandury/PycharmProjects/DL_project/data/clean_texts/1. Introduction_20251028_155541.txt** — === PAGE 1 === This project focuses on digitizing unstructured documents (PDFs or scanned uploads) and empowering users through translation, voice assistance, and an interactive chatbot. Users can upload documents, have them digitized and structured, and interactively learn about any word or sentence by clicking on it—triggering a right-side panel with explanations, translations, or voice playback...","You are LoanDocQA+, a factual retrieval assistant that answers questions accurately based on
the provided document context.

### Your Responsibilities
- Extract relevant facts only from the text below.
- If the document does not include the answer, clearly state:
  ""The document does not specify this information.""
- Answer in 1–3 sentences max.
- Maintain a professional, factual tone (no speculation).

### Example:
**User:** When does repayment start for Direct PLUS Loans?  
**You:** Repayment typically begins within 60 days of the final disbursement unless the borrower requests deferment while the student is enrolled.

Context:
=== PAGE 1 ===
This project focuses on digitizing unstructured documents (PDFs or scanned uploads) and
empowering users through translation, voice assistance, and an interactive chatbot. Users can
upload documents, have them digitized and structured, and interactively learn about any word
or sentence by clicking on it—triggering a right-side panel with explanations, translations, or
voice playback. The solution will be delivered as a web dashboard for maximum accessibility
and feature richness. A Chrome extension is considered for future scope.
We will use open-source OCR, translation, and language understanding datasets to train and
evaluate the system's ability to extract, translate, and explain document content. These
datasets are essential for robust digitization and user education features.
Field
Value
Size
10,000+ documents, 100,000+ sentences (varies by dataset)
Format
PDF, scanned images (JPG/PNG), text (TXT/JSON)
Data Types
Document images, extracted text, translations, audio
Languages
English, Hindi, Telugu, Spanish
Domains
Financial, legal, general
1. Introduction
2. Dataset Information
a) Dataset Introduction
b) Data Card
c) Data Sources
OCR:BhasaAnuvaad, IIIT-ILOCR
Translation:BhasaAnuvaad, CVSS
Language Understanding:SQuAD, IndicNLP
d) Data Rights and Privacy
All datasets are open-source and used for research/non-commercial purposes, with no PII
included.
User-uploaded documents will be processed securely, with encryption and access controls.


=== PAGE 2 ===
The system will comply with GDPR and similar regulations by anonymizing data, obtaining
user consent, and allowing data deletion on request.
3. Data Planning and Splits
Loading: Scripts to ingest PDFs/images, convert to text using OCR.
Preprocessing: Clean extracted text, segment sentences, detect language, and align with
translations.
Managing Data: Use version control (e.g., DVC), store metadata (language, domain,
source).
Splitting: 80% training, 10% validation, 10% test, stratified by language and document
type.
4. GitHub Repository
Link: (To be created, e.g., github.com/your-org/doc-digitizer)
Folder Structure:
/data/ — Data scripts and sample datasets
/ocr/ — OCR and preprocessing code
/translation/ — Translation and explanation modules
/voice/ — Voice synthesis and playback
/dashboard/ — Web dashboard code
/docs/ — Documentation and diagrams
/tests/ — Unit/integration tests
README.md — Overview, install, usage, contribution
5. Project Scope
a) Problems
Unstructured documents are hard to search, analyze, or understand.
Language barriers and complex terms hinder user comprehension.
Lack of interactive, accessible tools for document education.
b) Current Solutions
Basic OCR tools extract text but lack translation or explanation features.
Some web apps offer translation, but not interactive explanations or voice assistance.
No seamless browser-based solution for real-time document education.


=== PAGE 3 ===
Flowchart:
Bottlenecks:
Improvements:
c) Proposed Solutions
Digitize and structure documents using OCR and NLP.
Provide instant translation, voice playback, and chatbot explanations for any selected text.
Deliver as a web dashboard for easy access and integration (Chrome extension in future
scope).
6. Current Approach Flowchart and Bottleneck
Detection
1. User uploads PDF/scanned document
2. OCR extracts text and structure
3. ","The introductory document discusses a project aimed at digitizing unstructured documents, such as PDFs or scanned images (JPG/PNG), and making them interactive for users through translation, voice assistance, and an integrated chatbot. The goal is to empower users by allowing them to upload their own documents which will then be structured and made searchable with the ability to interactively learn about any word or sentence within a document via right-side panel explanations, translations, or audio playbacks. This solution intends to deliver as an accessible web dashboard while considering future expansion through a Chrome extension for additional functionality."
2025-10-28T16:28:22.742199,What is the interest rate mentioned?,integration-test,1.0,0,auto,0,0,mock,mock,mock
2025-10-28T16:28:22.753687,Explain the loan repayment period.,integration-test,1.0,0,auto,0,0,mock,mock,mock
2025-10-28T16:28:22.788040,Translate this document into Hindi.,integration-test,1.0,0,auto,0,0,mock,mock,mock
2025-10-28T16:28:22.798741,What is the collateral required?,integration-test,1.0,0,auto,0,0,mock,mock,mock
